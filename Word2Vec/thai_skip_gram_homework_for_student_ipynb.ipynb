{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ko8K6ntRi-W6"
   },
   "source": [
    "# Homework: Word Embedding\n",
    "\n",
    "In this exercise, you will work on the skip-gram neural network architecture for Word2Vec. You will be using Keras to train your model. \n",
    "\n",
    "The sample code for skip-gram model is given. Your job is to incorporate the tokenizer model that you created in HomeWork-1 to tokenize raw text and turn it into word vectors.\n",
    "\n",
    "You must complete the following tasks:\n",
    "1. Read/clean text files\n",
    "2. Indexing (Assign a number to each word)\n",
    "3. Create skip-grams (inputs for your model)\n",
    "4. Create the skip-gram neural network model\n",
    "5. Visualization\n",
    "6. Evaluation (Using pre-trained, not using pre-trained)\n",
    "    (classify topic from 4 categories) \n",
    "    \n",
    "This notebook assumes you have already installed Tensorflow and Keras with python3 and had GPU enabled. If you run this exercise on GCloud using the provided disk image you are all set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "colab_type": "code",
    "id": "Jw11OhLsi-W8",
    "outputId": "6983cc18-7e13-4c4a-8e31-de099186f743"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import glob\n",
    "import re\n",
    "import random\n",
    "import collections\n",
    "import os\n",
    "import sys\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import GRU, Dropout, Flatten\n",
    "from keras.models import load_model\n",
    "from keras.layers import Embedding, Reshape, Activation, Input, Dense, Masking\n",
    "from keras.layers.merge import Dot\n",
    "from keras.utils import np_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.preprocessing.sequence import skipgrams\n",
    "from keras.preprocessing import sequence\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RdYpL3Uyi-XD"
   },
   "source": [
    "## Step 1: Read/clean text files\n",
    "\n",
    "The given code can be used to processed the pre-tokenzied text file from the wikipedia corpus. In your homework, you must replace those text files with raw text files.  You must use your own tokenizer to process your text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Wco1eVRVzn6O",
    "outputId": "5c2954cf-19f1-47c9-a48d-1933360f928f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-02-23 06:29:08--  https://www.dropbox.com/s/eexden7246sgfzf/BEST-TrainingSet.zip\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.9.1, 2620:100:601f:1::a27d:901\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|162.125.9.1|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: /s/raw/eexden7246sgfzf/BEST-TrainingSet.zip [following]\n",
      "--2020-02-23 06:29:14--  https://www.dropbox.com/s/raw/eexden7246sgfzf/BEST-TrainingSet.zip\n",
      "Reusing existing connection to www.dropbox.com:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://uca99f59df488eaa81f5422d894b.dl.dropboxusercontent.com/cd/0/inline/AyqB52ofp0itcj4CZv59YrifPbFIfPBNDT0T-xjCqWcL4W-MHxE0vV5YUQdu2w_t-DAg7abfI7cjRZ86V7WaKk9mncBNx__fIzJRLI9YBY0WwizQv_dxQqXFVbbP1gmb5YQ/file# [following]\n",
      "--2020-02-23 06:29:14--  https://uca99f59df488eaa81f5422d894b.dl.dropboxusercontent.com/cd/0/inline/AyqB52ofp0itcj4CZv59YrifPbFIfPBNDT0T-xjCqWcL4W-MHxE0vV5YUQdu2w_t-DAg7abfI7cjRZ86V7WaKk9mncBNx__fIzJRLI9YBY0WwizQv_dxQqXFVbbP1gmb5YQ/file\n",
      "Resolving uca99f59df488eaa81f5422d894b.dl.dropboxusercontent.com (uca99f59df488eaa81f5422d894b.dl.dropboxusercontent.com)... 162.125.9.6, 2620:100:601f:6::a27d:906\n",
      "Connecting to uca99f59df488eaa81f5422d894b.dl.dropboxusercontent.com (uca99f59df488eaa81f5422d894b.dl.dropboxusercontent.com)|162.125.9.6|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 FOUND\n",
      "Location: /cd/0/inline2/AyryTzJ0RHKfIH2a44JV7yfA6HveECMvzIBvUqqcsv10mDmQtDoI3XvyUiF_EQDl_5o1nrBuIwyp2mmAAzsh9lIvK6reKwCFXl_0GR3YaMYx5ujx-OvU9igFuL_wUq6z-SyiT_tF2AKd0Gmw_AugGprxut9v99juwh2JBGmbcwzKmxToontq2XyW6SuFBB_I4Om6SIci3bYhFGXWFsOC-V-0FxR4kU8HSwEvlFsg_0nhh9TB3VqEJ9NoUUgn7jyFCClKQKeMapqjY1vJlh_WGNaoAeCikgYXNCF-5fb9yd4gOynMfOiQErJIuSn9laJ9J7VgdkS1Zx_GI6RrNiRw2mw8pzWYjGFL3AdyVHeftvqVBA/file [following]\n",
      "--2020-02-23 06:29:14--  https://uca99f59df488eaa81f5422d894b.dl.dropboxusercontent.com/cd/0/inline2/AyryTzJ0RHKfIH2a44JV7yfA6HveECMvzIBvUqqcsv10mDmQtDoI3XvyUiF_EQDl_5o1nrBuIwyp2mmAAzsh9lIvK6reKwCFXl_0GR3YaMYx5ujx-OvU9igFuL_wUq6z-SyiT_tF2AKd0Gmw_AugGprxut9v99juwh2JBGmbcwzKmxToontq2XyW6SuFBB_I4Om6SIci3bYhFGXWFsOC-V-0FxR4kU8HSwEvlFsg_0nhh9TB3VqEJ9NoUUgn7jyFCClKQKeMapqjY1vJlh_WGNaoAeCikgYXNCF-5fb9yd4gOynMfOiQErJIuSn9laJ9J7VgdkS1Zx_GI6RrNiRw2mw8pzWYjGFL3AdyVHeftvqVBA/file\n",
      "Reusing existing connection to uca99f59df488eaa81f5422d894b.dl.dropboxusercontent.com:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 13122229 (13M) [application/zip]\n",
      "Saving to: ‘BEST-TrainingSet.zip’\n",
      "\n",
      "BEST-TrainingSet.zi 100%[===================>]  12.51M  65.7MB/s    in 0.2s    \n",
      "\n",
      "2020-02-23 06:29:15 (65.7 MB/s) - ‘BEST-TrainingSet.zip’ saved [13122229/13122229]\n",
      "\n",
      "--2020-02-23 06:29:17--  https://www.dropbox.com/s/n87fiy25f2yc3gt/wiki.zip\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.9.1, 2620:100:601f:1::a27d:901\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|162.125.9.1|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: /s/raw/n87fiy25f2yc3gt/wiki.zip [following]\n",
      "--2020-02-23 06:29:17--  https://www.dropbox.com/s/raw/n87fiy25f2yc3gt/wiki.zip\n",
      "Reusing existing connection to www.dropbox.com:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://uc73985662b06a7004311472b4ad.dl.dropboxusercontent.com/cd/0/inline/AyrbrHs9ShJAZ6MOXP2zfsWyShOQiED7SR95dASTcKr_S2ZiwnKNENJKlXiEpDZTzENFBXvA_YOIIKTE5M0bBK6H8FnSZhVtLifaabY4nQjaUzMZ3deOdwf88bPh9CCUvzs/file# [following]\n",
      "--2020-02-23 06:29:18--  https://uc73985662b06a7004311472b4ad.dl.dropboxusercontent.com/cd/0/inline/AyrbrHs9ShJAZ6MOXP2zfsWyShOQiED7SR95dASTcKr_S2ZiwnKNENJKlXiEpDZTzENFBXvA_YOIIKTE5M0bBK6H8FnSZhVtLifaabY4nQjaUzMZ3deOdwf88bPh9CCUvzs/file\n",
      "Resolving uc73985662b06a7004311472b4ad.dl.dropboxusercontent.com (uc73985662b06a7004311472b4ad.dl.dropboxusercontent.com)... 162.125.9.6, 2620:100:601f:6::a27d:906\n",
      "Connecting to uc73985662b06a7004311472b4ad.dl.dropboxusercontent.com (uc73985662b06a7004311472b4ad.dl.dropboxusercontent.com)|162.125.9.6|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 FOUND\n",
      "Location: /cd/0/inline2/AyrQlejte7Jd7muCKOXtkB55eDFimnzC0FLQXkJ5vSKtGgsW6XNBpx4iTjRuomPgzO3O47QoQbHvCEmPeZPXloAARfIKZDxWFSHKmzOM6AE9huMTziO-vZFGdOdSs9aHl77VyusYUaEoaFMtMHPnzU46zpWoSG8pB1Q41v4qD4JPBfZ_a2rqfX-G_0Fu_6yNslZD-Cb9tSlyNT_22wreKML0D9aH03YZOH2gsJWMDjvLub1ZoHyyow_Zw9qtHYYlg4y9Zvy6_ZesMShtgYlNEe4UV2PWEoVtJ2WRVXVWs37z76ytXcTaLyx0qKYNTOzJEWILy2yhPwg6ILMsjD4C4s-5kZRxcmU709kHMxGrSTQ0GQ/file [following]\n",
      "--2020-02-23 06:29:18--  https://uc73985662b06a7004311472b4ad.dl.dropboxusercontent.com/cd/0/inline2/AyrQlejte7Jd7muCKOXtkB55eDFimnzC0FLQXkJ5vSKtGgsW6XNBpx4iTjRuomPgzO3O47QoQbHvCEmPeZPXloAARfIKZDxWFSHKmzOM6AE9huMTziO-vZFGdOdSs9aHl77VyusYUaEoaFMtMHPnzU46zpWoSG8pB1Q41v4qD4JPBfZ_a2rqfX-G_0Fu_6yNslZD-Cb9tSlyNT_22wreKML0D9aH03YZOH2gsJWMDjvLub1ZoHyyow_Zw9qtHYYlg4y9Zvy6_ZesMShtgYlNEe4UV2PWEoVtJ2WRVXVWs37z76ytXcTaLyx0qKYNTOzJEWILy2yhPwg6ILMsjD4C4s-5kZRxcmU709kHMxGrSTQ0GQ/file\n",
      "Reusing existing connection to uc73985662b06a7004311472b4ad.dl.dropboxusercontent.com:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 92415438 (88M) [application/zip]\n",
      "Saving to: ‘wiki.zip’\n",
      "\n",
      "wiki.zip            100%[===================>]  88.13M  29.3MB/s    in 3.0s    \n",
      "\n",
      "2020-02-23 06:29:22 (29.3 MB/s) - ‘wiki.zip’ saved [92415438/92415438]\n",
      "\n",
      "Archive:  wiki.zip\n",
      "   creating: wiki/\n",
      "  inflating: __MACOSX/._wiki         \n",
      "  inflating: wiki/thwiki_chk.txt     \n",
      "  inflating: __MACOSX/wiki/._thwiki_chk.txt  \n",
      "Archive:  BEST-TrainingSet.zip\n",
      "   creating: BEST-TrainingSet/\n",
      "  inflating: __MACOSX/._BEST-TrainingSet  \n",
      "  inflating: BEST-TrainingSet/.DS_Store  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/._.DS_Store  \n",
      "   creating: BEST-TrainingSet/encyclopedia/\n",
      "  inflating: __MACOSX/BEST-TrainingSet/._encyclopedia  \n",
      "   creating: BEST-TrainingSet/novel/\n",
      "  inflating: __MACOSX/BEST-TrainingSet/._novel  \n",
      "   creating: BEST-TrainingSet/news/\n",
      "  inflating: __MACOSX/BEST-TrainingSet/._news  \n",
      "   creating: BEST-TrainingSet/article/\n",
      "  inflating: __MACOSX/BEST-TrainingSet/._article  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00031.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00031.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00025.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00025.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00019.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00019.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00018.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00018.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00024.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00024.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00030.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00030.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00026.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00026.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00032.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00032.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00033.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00033.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00027.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00027.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00023.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00023.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00037.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00037.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00036.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00036.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00022.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00022.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00008.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00008.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00034.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00034.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00020.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00020.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00021.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00021.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00035.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00035.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00009.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00009.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00052.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00052.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00046.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00046.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00091.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00091.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00085.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00085.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00084.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00084.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00090.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00090.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00047.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00047.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00053.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00053.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00045.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00045.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00051.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00051.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00079.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00079.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00086.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00086.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00092.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00092.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00093.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00093.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00087.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00087.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00078.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00078.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00050.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00050.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00044.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00044.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00108.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00108.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00068.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00068.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00040.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00040.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00054.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00054.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00083.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00083.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00097.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00097.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00096.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00096.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00082.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00082.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00055.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00055.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00041.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00041.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00069.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00069.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00057.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00057.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00043.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00043.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00094.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00094.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00080.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00080.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00081.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00081.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00095.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00095.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00042.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00042.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00056.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00056.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00107.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00107.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00073.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00073.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00067.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00067.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00098.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00098.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00099.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00099.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00066.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00066.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00072.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00072.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00106.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00106.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00104.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00104.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00064.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00064.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00070.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00070.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00058.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00058.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00059.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00059.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00071.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00071.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00065.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00065.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00105.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00105.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00101.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00101.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00049.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00049.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00061.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00061.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00075.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00075.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00074.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00074.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00060.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00060.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00048.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00048.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00100.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00100.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00102.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00102.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00076.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00076.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00062.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00062.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00089.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00089.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00088.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00088.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00063.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00063.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00077.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00077.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00103.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00103.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00010.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00010.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00004.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00004.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00038.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00038.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00039.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00039.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00005.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00005.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00011.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00011.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00007.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00007.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00013.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00013.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00012.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00012.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00006.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00006.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00002.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00002.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00016.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00016.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00017.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00017.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00003.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00003.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00029.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00029.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00015.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00015.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00001.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00001.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00014.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00014.txt  \n",
      "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00028.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00028.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00089.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00089.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00076.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00076.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00062.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00062.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00102.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00102.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00103.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00103.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00063.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00063.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00077.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00077.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00088.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00088.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00061.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00061.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00075.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00075.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00049.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00049.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00101.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00101.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00100.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00100.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00048.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00048.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00074.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00074.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00060.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00060.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00058.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00058.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00064.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00064.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00070.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00070.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00104.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00104.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00105.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00105.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00071.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00071.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00065.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00065.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00059.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00059.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00098.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00098.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00073.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00073.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00067.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00067.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00107.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00107.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00106.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00106.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00066.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00066.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00072.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00072.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00099.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00099.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00015.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00015.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00001.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00001.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00029.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00029.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00028.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00028.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00014.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00014.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00002.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00002.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00016.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00016.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00017.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00017.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00003.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00003.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00007.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00007.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00013.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00013.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00012.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00012.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00006.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00006.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00038.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00038.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00010.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00010.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00004.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00004.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00005.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00005.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00011.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00011.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00039.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00039.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00034.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00034.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00020.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00020.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00008.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00008.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00009.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00009.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00021.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00021.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00035.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00035.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00023.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00023.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00037.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00037.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00036.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00036.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00022.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00022.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00026.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00026.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00032.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00032.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00033.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00033.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00027.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00027.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00019.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00019.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00031.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00031.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00025.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00025.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00024.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00024.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00030.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00030.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00018.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00018.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00094.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00094.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00080.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00080.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00057.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00057.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00043.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00043.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00042.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00042.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00056.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00056.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00081.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00081.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00095.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00095.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00083.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00083.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00097.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00097.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00040.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00040.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00054.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00054.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00068.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00068.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00069.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00069.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00055.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00055.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00041.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00041.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00096.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00096.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00082.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00082.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00086.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00086.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00092.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00092.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00079.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00079.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00045.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00045.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00051.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00051.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00050.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00050.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00044.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00044.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00078.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00078.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00093.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00093.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00087.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00087.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00091.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00091.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00085.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00085.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00052.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00052.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00046.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00046.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00047.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00047.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00053.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00053.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00084.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00084.txt  \n",
      "  inflating: BEST-TrainingSet/novel/novel_00090.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00090.txt  \n",
      "  inflating: BEST-TrainingSet/news/news_00073.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00073.txt  \n",
      "  inflating: BEST-TrainingSet/news/news_00067.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00067.txt  \n",
      "  inflating: BEST-TrainingSet/news/news_00066.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00066.txt  \n",
      "  inflating: BEST-TrainingSet/news/news_00072.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00072.txt  \n",
      "  inflating: BEST-TrainingSet/news/news_00058.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00058.txt  \n",
      "  inflating: BEST-TrainingSet/news/news_00064.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00064.txt  \n",
      "  inflating: BEST-TrainingSet/news/news_00070.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00070.txt  \n",
      "  inflating: BEST-TrainingSet/news/news_00071.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00071.txt  \n",
      "  inflating: BEST-TrainingSet/news/news_00065.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00065.txt  \n",
      "  inflating: BEST-TrainingSet/news/news_00059.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00059.txt  \n",
      "  inflating: BEST-TrainingSet/news/news_00061.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00061.txt  \n",
      "  inflating: BEST-TrainingSet/news/news_00075.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00075.txt  \n",
      "  inflating: BEST-TrainingSet/news/news_00049.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00049.txt  \n",
      "  inflating: BEST-TrainingSet/news/news_00048.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00048.txt  \n",
      "  inflating: BEST-TrainingSet/news/news_00074.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00074.txt  \n",
      "  inflating: BEST-TrainingSet/news/news_00060.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00060.txt  \n",
      "  inflating: BEST-TrainingSet/news/news_00076.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00076.txt  \n",
      "  inflating: BEST-TrainingSet/news/news_00062.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00062.txt  \n",
      "  inflating: BEST-TrainingSet/news/news_00089.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00089.txt  \n",
      "  inflating: BEST-TrainingSet/news/news_00088.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00088.txt  \n",
      "  inflating: BEST-TrainingSet/news/news_00063.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00063.txt  \n",
      "  inflating: BEST-TrainingSet/news/news_00077.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00077.txt  \n",
      "  inflating: BEST-TrainingSet/news/news_00038.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00038.txt  \n",
      "  inflating: BEST-TrainingSet/news/news_00010.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00010.txt  \n",
      "  inflating: BEST-TrainingSet/news/news_00004.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00004.txt  \n",
      "  inflating: BEST-TrainingSet/news/news_00005.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00005.txt  \n",
      "  inflating: BEST-TrainingSet/news/news_00011.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00011.txt  \n",
      "  inflating: BEST-TrainingSet/news/news_00039.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00039.txt  \n",
      "  inflating: BEST-TrainingSet/news/news_00007.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00007.txt  \n",
      "  inflating: BEST-TrainingSet/news/news_00013.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00013.txt  \n",
      "  inflating: BEST-TrainingSet/news/news_00012.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00012.txt  \n",
      "  inflating: BEST-TrainingSet/news/news_00006.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00006.txt  \n",
      "  inflating: BEST-TrainingSet/news/news_00002.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00002.txt  \n",
      "  inflating: BEST-TrainingSet/news/news_00016.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00016.txt  \n",
      "  inflating: BEST-TrainingSet/news/news_00017.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00017.txt  \n",
      "  inflating: BEST-TrainingSet/news/news_00003.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00003.txt  \n",
      "  inflating: BEST-TrainingSet/news/news_00015.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00015.txt  \n",
      "  inflating: BEST-TrainingSet/news/news_00001.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00001.txt  \n",
      "  inflating: BEST-TrainingSet/news/news_00029.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00029.txt  \n",
      "  inflating: BEST-TrainingSet/news/news_00028.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00028.txt  \n",
      "  inflating: BEST-TrainingSet/news/news_00014.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00014.txt  \n",
      "  inflating: BEST-TrainingSet/news/news_00019.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00019.txt  \n",
      "  inflating: BEST-TrainingSet/news/news_00031.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00031.txt  \n",
      "  inflating: BEST-TrainingSet/news/news_00025.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00025.txt  \n",
      "  inflating: BEST-TrainingSet/news/news_00024.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00024.txt  \n",
      "  inflating: BEST-TrainingSet/news/news_00030.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00030.txt  \n",
      "  inflating: BEST-TrainingSet/news/news_00018.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00018.txt  \n",
      "  inflating: BEST-TrainingSet/news/news_00026.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00026.txt  \n",
      "  inflating: BEST-TrainingSet/news/news_00032.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00032.txt  \n",
      "  inflating: BEST-TrainingSet/news/news_00033.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00033.txt  \n",
      "  inflating: BEST-TrainingSet/news/news_00027.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00027.txt  \n",
      "  inflating: BEST-TrainingSet/news/news_00023.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00023.txt  \n",
      "  inflating: BEST-TrainingSet/news/news_00037.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00037.txt  \n",
      "  inflating: BEST-TrainingSet/news/news_00036.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00036.txt  \n",
      "  inflating: BEST-TrainingSet/news/news_00022.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00022.txt  \n",
      "  inflating: BEST-TrainingSet/news/news_00034.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00034.txt  \n",
      "  inflating: BEST-TrainingSet/news/news_00020.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00020.txt  \n",
      "  inflating: BEST-TrainingSet/news/news_00008.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00008.txt  \n",
      "  inflating: BEST-TrainingSet/news/news_00009.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00009.txt  \n",
      "  inflating: BEST-TrainingSet/news/news_00021.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00021.txt  \n",
      "  inflating: BEST-TrainingSet/news/news_00035.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00035.txt  \n",
      "  inflating: BEST-TrainingSet/news/news_00052.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00052.txt  \n",
      "  inflating: BEST-TrainingSet/news/news_00046.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00046.txt  \n",
      "  inflating: BEST-TrainingSet/news/news_00091.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00091.txt  \n",
      "  inflating: BEST-TrainingSet/news/news_00085.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00085.txt  \n",
      "  inflating: BEST-TrainingSet/news/news_00084.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00084.txt  \n",
      "  inflating: BEST-TrainingSet/news/news_00090.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00090.txt  \n",
      "  inflating: BEST-TrainingSet/news/news_00047.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00047.txt  \n",
      "  inflating: BEST-TrainingSet/news/news_00053.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00053.txt  \n",
      "  inflating: BEST-TrainingSet/news/news_00079.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00079.txt  \n",
      "  inflating: BEST-TrainingSet/news/news_00045.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00045.txt  \n",
      "  inflating: BEST-TrainingSet/news/news_00051.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00051.txt  \n",
      "  inflating: BEST-TrainingSet/news/news_00086.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00086.txt  \n",
      "  inflating: BEST-TrainingSet/news/news_00092.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00092.txt  \n",
      "  inflating: BEST-TrainingSet/news/news_00093.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00093.txt  \n",
      "  inflating: BEST-TrainingSet/news/news_00087.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00087.txt  \n",
      "  inflating: BEST-TrainingSet/news/news_00050.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00050.txt  \n",
      "  inflating: BEST-TrainingSet/news/news_00044.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00044.txt  \n",
      "  inflating: BEST-TrainingSet/news/news_00078.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00078.txt  \n",
      "  inflating: BEST-TrainingSet/news/news_00040.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00040.txt  \n",
      "  inflating: BEST-TrainingSet/news/news_00054.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00054.txt  \n",
      "  inflating: BEST-TrainingSet/news/news_00068.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00068.txt  \n",
      "  inflating: BEST-TrainingSet/news/news_00083.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00083.txt  \n",
      "  inflating: BEST-TrainingSet/news/news_00096.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00096.txt  \n",
      "  inflating: BEST-TrainingSet/news/news_00082.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00082.txt  \n",
      "  inflating: BEST-TrainingSet/news/news_00069.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00069.txt  \n",
      "  inflating: BEST-TrainingSet/news/news_00055.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00055.txt  \n",
      "  inflating: BEST-TrainingSet/news/news_00041.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00041.txt  \n",
      "  inflating: BEST-TrainingSet/news/news_00057.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00057.txt  \n",
      "  inflating: BEST-TrainingSet/news/news_00043.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00043.txt  \n",
      "  inflating: BEST-TrainingSet/news/news_00094.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00094.txt  \n",
      "  inflating: BEST-TrainingSet/news/news_00080.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00080.txt  \n",
      "  inflating: BEST-TrainingSet/news/news_00081.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00081.txt  \n",
      "  inflating: BEST-TrainingSet/news/news_00095.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00095.txt  \n",
      "  inflating: BEST-TrainingSet/news/news_00042.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00042.txt  \n",
      "  inflating: BEST-TrainingSet/news/news_00056.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00056.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00011.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00011.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00005.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00005.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00039.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00039.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00165.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00165.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00171.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00171.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00159.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00159.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00158.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00158.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00170.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00170.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00164.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00164.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00038.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00038.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00004.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00004.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00010.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00010.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00006.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00006.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00012.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00012.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00172.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00172.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00166.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00166.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00198.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00198.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00167.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00167.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00173.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00173.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00013.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00013.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00007.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00007.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00003.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00003.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00017.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00017.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00177.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00177.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00163.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00163.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00188.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00188.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00189.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00189.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00162.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00162.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00176.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00176.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00016.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00016.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00002.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00002.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00028.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00028.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00014.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00014.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00148.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00148.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00160.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00160.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00174.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00174.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00175.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00175.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00161.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00161.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00149.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00149.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00001.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00001.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00015.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00015.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00029.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00029.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00072.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00072.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00066.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00066.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00099.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00099.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00106.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00106.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00112.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00112.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00113.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00113.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00107.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00107.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00098.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00098.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00073.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00073.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00065.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00065.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00071.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00071.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00059.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00059.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00111.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00111.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00105.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00105.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00139.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00139.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00138.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00138.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00104.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00104.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00110.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00110.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00070.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00070.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00064.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00064.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00048.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00048.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00060.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00060.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00074.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00074.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00128.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00128.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00114.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00114.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00100.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00100.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00101.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00101.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00115.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00115.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00129.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00129.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00075.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00075.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00061.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00061.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00049.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00049.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00077.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00077.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00063.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00063.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00088.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00088.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00103.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00103.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00117.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00117.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00116.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00116.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00102.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00102.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00089.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00089.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00062.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00062.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00076.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00076.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00053.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00053.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00047.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00047.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00090.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00090.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00084.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00084.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00127.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00127.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00133.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00133.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00132.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00132.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00126.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00126.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00085.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00085.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00091.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00091.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00046.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00046.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00052.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00052.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00044.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00044.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00050.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00050.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00078.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00078.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00087.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00087.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00093.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00093.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00130.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00130.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00124.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00124.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00118.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00118.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00119.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00119.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00125.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00125.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00131.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00131.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00092.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00092.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00086.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00086.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00079.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00079.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00051.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00051.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00045.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00045.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00069.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00069.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00041.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00041.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00055.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00055.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00082.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00082.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00096.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00096.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00109.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00109.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00135.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00135.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00121.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00121.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00120.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00120.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00134.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00134.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00108.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00108.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00097.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00097.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00083.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00083.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00054.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00054.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00040.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00040.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00068.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00068.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00056.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00056.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00042.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00042.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00095.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00095.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00081.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00081.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00122.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00122.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00136.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00136.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00137.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00137.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00123.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00123.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00080.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00080.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00094.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00094.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00043.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00043.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00057.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00057.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00030.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00030.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00024.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00024.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00018.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00018.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00144.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00144.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00150.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00150.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00178.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00178.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00187.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00187.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00193.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00193.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00192.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00192.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00186.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00186.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00179.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00179.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00151.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00151.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00145.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00145.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00019.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00019.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00025.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00025.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00031.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00031.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00027.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00027.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00033.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00033.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00153.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00153.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00147.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00147.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00190.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00190.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00184.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00184.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00185.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00185.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00191.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00191.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00146.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00146.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00152.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00152.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00032.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00032.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00026.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00026.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00022.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00022.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00036.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00036.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00156.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00156.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00142.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00142.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00195.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00195.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00181.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00181.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00180.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00180.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00194.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00194.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00143.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00143.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00157.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00157.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00037.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00037.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00023.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00023.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00009.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00009.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00035.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00035.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00021.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00021.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00169.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00169.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00141.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00141.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00155.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00155.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00196.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00196.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00197.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00197.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00183.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00183.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00154.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00154.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00140.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00140.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00168.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00168.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00020.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00020.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00034.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00034.txt  \n",
      "  inflating: BEST-TrainingSet/article/article_00008.txt  \n",
      "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00008.txt  \n"
     ]
    }
   ],
   "source": [
    "!wget https://www.dropbox.com/s/eexden7246sgfzf/BEST-TrainingSet.zip\n",
    "!wget https://www.dropbox.com/s/n87fiy25f2yc3gt/wiki.zip\n",
    "!unzip wiki.zip\n",
    "!unzip BEST-TrainingSet.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mOrcjHnui-XF"
   },
   "outputs": [],
   "source": [
    "#Step 1: read the wikipedia text file\n",
    "with open(\"wiki/thwiki_chk.txt\") as f:\n",
    "    raw_text = [] \n",
    "    #The text file is already tokenized BUT...\n",
    "    #we've replaced all the spaces between words, so you have to use your tokenizer.\n",
    "    raw_text.extend(re.sub(r\"\\s+\",\"\",f.read()))\n",
    "    #since the wiki file is very large, we will only use 1/20 of the whole wiki file in this homework\n",
    "    # if you have enough memeory and want to add more training data, please feel free to edit this code\n",
    "    # to include more data\n",
    "    raw_text = raw_text[:len(raw_text)//20]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MnMg7OiZi-XL"
   },
   "outputs": [],
   "source": [
    "# Create a character map\n",
    "CHARS = [\n",
    "  '\\n', ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+',\n",
    "  ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8',\n",
    "  '9', ':', ';', '<', '=', '>', '?', '@', 'A', 'B', 'C', 'D', 'E',\n",
    "  'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R',\n",
    "  'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', '\\\\', ']', '^', '_',\n",
    "  'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm',\n",
    "  'n', 'o', 'other', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y',\n",
    "  'z', '}', '~', 'ก', 'ข', 'ฃ', 'ค', 'ฅ', 'ฆ', 'ง', 'จ', 'ฉ', 'ช',\n",
    "  'ซ', 'ฌ', 'ญ', 'ฎ', 'ฏ', 'ฐ', 'ฑ', 'ฒ', 'ณ', 'ด', 'ต', 'ถ', 'ท',\n",
    "  'ธ', 'น', 'บ', 'ป', 'ผ', 'ฝ', 'พ', 'ฟ', 'ภ', 'ม', 'ย', 'ร', 'ฤ',\n",
    "  'ล', 'ว', 'ศ', 'ษ', 'ส', 'ห', 'ฬ', 'อ', 'ฮ', 'ฯ', 'ะ', 'ั', 'า',\n",
    "  'ำ', 'ิ', 'ี', 'ึ', 'ื', 'ุ', 'ู', 'ฺ', 'เ', 'แ', 'โ', 'ใ', 'ไ',\n",
    "  'ๅ', 'ๆ', '็', '่', '้', '๊', '๋', '์', 'ํ', '๐', '๑', '๒', '๓',\n",
    "  '๔', '๕', '๖', '๗', '๘', '๙', '‘', '’', '\\ufeff'\n",
    "]\n",
    "CHARS_MAP = {v: k for k, v in enumerate(CHARS)}\n",
    "char = np.array(CHARS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zhCnjdO3i-XQ"
   },
   "outputs": [],
   "source": [
    "def create_n_gram_df(df, n_pad):\n",
    "  \"\"\"\n",
    "  Given an input dataframe, create a feature dataframe of shifted characters\n",
    "  Input:\n",
    "  df: timeseries of size (N)\n",
    "  n_pad: the number of context. For a given character at position [idx],\n",
    "    character at position [idx-n_pad/2 : idx+n_pad/2] will be used \n",
    "    as features for that character.\n",
    "  \n",
    "  Output:\n",
    "  dataframe of size (N * n_pad) which each row contains the character, \n",
    "    n_pad_2 characters to the left, and n_pad_2 characters to the right\n",
    "    of that character.\n",
    "  \"\"\"\n",
    "  n_pad_2 = int((n_pad - 1)/2)\n",
    "  for i in range(n_pad_2):\n",
    "      df['char-{}'.format(i+1)] = df['char'].shift(i + 1)\n",
    "      df['char{}'.format(i+1)] = df['char'].shift(-i - 1)\n",
    "  return df[n_pad_2: -n_pad_2]\n",
    "\n",
    "\n",
    "def prepare_wiki_feature(raw_text_input):\n",
    "    \"\"\"\n",
    "    Transform the path to a directory containing processed files \n",
    "    into a feature matrix and output array\n",
    "    \"\"\"\n",
    "    # we use padding equals 21 here to consider 10 characters to the left\n",
    "    # and 10 characters to the right as features for the character in the middle\n",
    "    n_pad = 21\n",
    "    n_pad_2 = int((n_pad - 1)/2)\n",
    "    pad = [{'char': ' ', 'target': True}]\n",
    "    df_pad = pd.DataFrame(pad * n_pad_2)\n",
    "\n",
    "    df = []\n",
    "\n",
    "    df.append(pd.DataFrame(  {'char': raw_text_input}))\n",
    "\n",
    "    df = pd.concat(df)\n",
    "    # pad with empty string feature\n",
    "    df = pd.concat((df_pad, df, df_pad))\n",
    "\n",
    "    # map characters to numbers, use 'other' if not in the predefined character set.\n",
    "    df['char'] = df['char'].map(lambda x: CHARS_MAP.get(x, 80))\n",
    "\n",
    "    # Use nearby characters as features\n",
    "    df_with_context = create_n_gram_df(df, n_pad=n_pad)\n",
    "\n",
    "    char_row = ['char' + str(i + 1) for i in range(n_pad_2)] + \\\n",
    "             ['char-' + str(i + 1) for i in range(n_pad_2)] + ['char']\n",
    "\n",
    "    # convert pandas dataframe to numpy array to feed to the model\n",
    "    x_char = df_with_context[char_row].as_matrix()\n",
    "\n",
    "    return x_char\n",
    "\n",
    "#A function for displaying our features in text\n",
    "def print_features(tfeature,index):\n",
    "    feature = np.array(tfeature[index],dtype=int).reshape(21,1)\n",
    "    #Convert to string\n",
    "    char_list = char[feature]\n",
    "    left = ''.join(reversed(char_list[10:20].reshape(10))).replace(\" \", \"\")\n",
    "    center = ''.join(char_list[20])\n",
    "    right =  ''.join(char_list[0:10].reshape(10)).replace(\" \", \"\")\n",
    "    word = ''.join([left,' ',center,' ',right])\n",
    "    print(center + ': ' + word )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OBclVCXxi-XU"
   },
   "source": [
    "## <font color='blue'>Homework Question1:</font>\n",
    "<font color='blue'>Use your own tokenizer (aka word segmentation model)  to define word boundaries and split the given text file into words. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 615
    },
    "colab_type": "code",
    "id": "ej9Tok5wi-XV",
    "outputId": "703c4ec9-3e3a-42b4-dc0f-647c0a0be3c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 21)                0         \n",
      "_________________________________________________________________\n",
      "embedding_3 (Embedding)      (None, 21, 32)            5696      \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 32)                6336      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               16896     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 160,513\n",
      "Trainable params: 160,513\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# TODO#1 \n",
    "#load your word segmentation model here!\n",
    "def get_your_nn():\n",
    "  input1 = Input(shape=(21,))\n",
    "  x = Embedding(178,32,input_length=21)(input1)\n",
    "  x = GRU(32,reset_after=True)(x)\n",
    "  x = Dense(512, activation='relu')(x)\n",
    "  x = Dropout(0.2)(x)\n",
    "  x = Dense(256, activation='relu')(x)\n",
    "  out = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "  model = Model(inputs=input1, outputs=out)\n",
    "  model.compile(optimizer=Adam(),\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['acc'])\n",
    "  \n",
    "  model.load_weights('/content/model_weight_nn.h5')\n",
    "  model.summary()\n",
    "  return model\n",
    "\n",
    "model = get_your_nn()\n",
    "\n",
    "#load weights here/ or alternatively you can also load your entire model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "fMkvrgu5i-Xb",
    "outputId": "99c71640-7f6c-4d71-f34d-ef6ab61c45bd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:40: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:51: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " data shape:  (7592023, 21)\n"
     ]
    }
   ],
   "source": [
    "x_char= prepare_wiki_feature(raw_text)\n",
    "#feel free to edit prepare_wiki_feature if your model has different input format\n",
    "# As a sanity check, we print out the size of the data.\n",
    "print(' data shape: ', x_char.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mMbP8-5Vi-Xe"
   },
   "outputs": [],
   "source": [
    "def char_to_word(raw_text, y_pred):\n",
    "    \"\"\" add spaces between words in the raw text based on your prediction\n",
    "    \"\"\"\n",
    "    split_text=\"\"\n",
    "    for char, y in zip(raw_text,y_pred):\n",
    "        if y == 1:\n",
    "            split_text+=\" \"\n",
    "            split_text+=char\n",
    "        else:\n",
    "            split_text+=char\n",
    "    return split_text.split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NS7iDdVYi-Xj"
   },
   "outputs": [],
   "source": [
    "####TOKENIZATION\n",
    "###THIS MIGHT TAKE ABOUT 10 MINS on feed forward models\n",
    "y_pred = model.predict(x_char)\n",
    "prob_to_class = lambda p: 1 if p[0]>=0.5 else 0\n",
    "y_pred = np.apply_along_axis(prob_to_class,1,y_pred)\n",
    "del x_char #clear up some memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "BIwa4qJoi-Xl",
    "outputId": "4ad7e2cf-83ec-4efc-999c-628615fa33cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'หน้า', 'หลัก', 'วิกิพีเดีย', 'ดำเนินการ', 'โดยมูลนิธิวิกิมี', 'เดีย', 'องค์กร', 'ไม่', 'แสวง', 'ผล', 'กำไร', 'ผู้', 'ดำเนินการ', 'อีก', 'หลาย', 'ได้', 'แก่__NOEDITSECTION__', 'ดาราศาสตร์', 'ดาราศาสตร์', 'คือวิชาวิทยาศาสตร์', 'ที่', 'ศึกษาวัตถุท้องฟ้า', '(', 'อาทิ', 'ดาวฤกษ์', 'ดาว', 'เคราะห์', 'ดาว', 'หาง', 'และ', 'ดาราจักร', ')', 'รวม', 'ทั้ง', 'ปรากฏการณ์', 'ทาง', 'ธรรมชาติ', 'ต่างๆ', 'ที่', 'เกิด', 'ขึ้น', 'จาก', 'นอก', 'ชั้น', 'บรรยากาศ', 'ของ', 'โลก', 'โดย', 'ศึกษา', 'เกี่ยว', 'กับ', 'วิวัฒนาการลักษณะ', 'ทาง', 'กายภาพ', 'ทาง', 'เคมี', 'ทาง', 'อุตุนิยมวิทยา', 'และ', 'การ', 'เคลื่อน', 'ที่', 'ของ', 'วัตถุ', 'ท้องฟ้า', 'ตลอดจน', 'ถึง', 'การ', 'กำเนิด', 'และ', 'วิวัฒนาการ', 'ของ', 'เอกภพดาราศาสตร์', 'เป็น', 'หนึ่ง', 'ใน', 'สาขา', 'ของ', 'วิทยาศาสตร์', 'ที่', 'เก่า', 'แก่', 'ที่สุด', 'นักดาราศาสตร์', 'ใน', 'วัฒนธรรม', 'โบราณ', 'สังเกตการณ์', 'ดวง', 'ดาว', 'บน', 'ท้องฟ้า', 'ใน', 'เวลากลาง', 'คืน', 'และ', 'วัตถุ', 'ทาง', 'ดาราศาสตร์']\n"
     ]
    }
   ],
   "source": [
    "tokens= char_to_word(raw_text, y_pred)\n",
    "#print out first 100 words for sanity check\n",
    "print(tokens[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "uPDK1fkxi-Xp",
    "outputId": "73220f91-80f6-4399-dde3-7a35cc160517"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total word count: 1707140\n"
     ]
    }
   ],
   "source": [
    "print(\"total word count:\", len(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GDVMvTRci-Xu"
   },
   "source": [
    "## Step 2: Indexing (Assign a number to each word)\n",
    "\n",
    "The code below generates an indexed dataset(each word is represented by a number), a dictionary, a reversed dictionary\n",
    "\n",
    "## <font color='blue'>Homework Question 2:</font>\n",
    "<font color='blue'>“UNK” is often used to represent an unknown word (a word which does not exist in your dictionary/training set). You can also represent a rare word with this token as well.  How do you define a rare word in your program? Explain in your own words and capture the screenshot of your code segment that is a part of this process</font>\n",
    "\n",
    " + <font color='blue'>edit or replace create_index with your own code to set a threshold for rare words and replace them with \"UNK\"</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "O6NP7nQGi-Xw",
    "outputId": "4cd70c66-b347-475d-af5f-2e7a1aa3a90d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ที่', 46831), ('ใน', 43820), ('เป็น', 35842), ('และ', 35524), ('การ', 34916), ('ของ', 33581), ('มี', 29459), ('ได้', 24652), ('\"', 18158), (')', 17556)]\n"
     ]
    }
   ],
   "source": [
    "#step 2:Build dictionary and build a dataset(replace each word with its index)\n",
    "def create_index(input_text):\n",
    "    # TODO#2:edit or replace this function\n",
    "    words = [word for word in input_text ]\n",
    "    word_count = list()\n",
    "    #use set and len to get the number of unique words\n",
    "    word_count.extend(collections.Counter(words).most_common(len(set(words))))\n",
    "    #include a token for unknown word\n",
    "    word_count.append((\"UNK\",0))\n",
    "    #print out 10 most frequent words\n",
    "    print(word_count[:10])\n",
    "    dictionary = dict()\n",
    "    dictionary[\"for_keras_zero_padding\"] = 0\n",
    "    for word in word_count:\n",
    "        dictionary[word[0]] = len(dictionary)\n",
    "    reverse_dictionary = dict(zip(dictionary.values(), dictionary.keys()))\n",
    "    data = list()\n",
    "    for word in input_text:\n",
    "        data.append(dictionary[word])\n",
    "\n",
    "    return data,dictionary, reverse_dictionary\n",
    "\n",
    "dataset,dictionary, reverse_dictionary=create_index(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "2fotaYMgi-Xz",
    "outputId": "7cbe2e2a-f20f-4747-8c38-18642df7766e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output sample (dataset): [30475, 303, 178, 1046, 2338, 18726, 3088, 1120, 26, 6817]\n",
      "output sample (dictionary): {'for_keras_zero_padding': 0, 'ที่': 1, 'ใน': 2, 'เป็น': 3, 'และ': 4, 'การ': 5, 'ของ': 6, 'มี': 7, 'ได้': 8, '\"': 9}\n",
      "output sample (reverse dictionary): {0: 'for_keras_zero_padding', 1: 'ที่', 2: 'ใน', 3: 'เป็น', 4: 'และ', 5: 'การ', 6: 'ของ', 7: 'มี', 8: 'ได้', 9: '\"'}\n"
     ]
    }
   ],
   "source": [
    "print(\"output sample (dataset):\",dataset[:10])\n",
    "print(\"output sample (dictionary):\",{k: dictionary[k] for k in list(dictionary)[:10]})\n",
    "print(\"output sample (reverse dictionary):\",{k: reverse_dictionary[k] for k in list(reverse_dictionary)[:10]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "PtFyCpcNi-X1",
    "outputId": "04d4b9c4-baf8-4304-ccb3-7fced17f0488"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112106"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HutTzPO7i-X3"
   },
   "source": [
    "# Step3: Create skip-grams (inputs for your model)\n",
    "Keras has a skipgrams-generator, the cell below shows us how it generates skipgrams \n",
    "\n",
    "## <font color='blue'>Homework Question 3:</font>\n",
    "<font color='blue'>The negative samples are sampled from sampling_table.  Look through Keras source code to find out how they sample negative samples. Discuss the sampling technique taught in class and compare it to the Keras source code.</font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190
    },
    "colab_type": "code",
    "id": "C520WnI0i-X4",
    "outputId": "311b2ca8-e483-478c-e857-f3193d8047c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[30475, 91507], [18726, 3088], [18726, 2338], [1046, 2338], [30475, 303], [303, 178], [303, 105621], [1046, 178], [6817, 26], [1120, 3088], [1120, 852], [1046, 44598], [1120, 26], [18726, 99459], [303, 30475], [1120, 106094], [18726, 36464], [1046, 20927], [6817, 55393], [303, 77237]] [0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0]\n",
      " โอกาสการคลอดลูก\n",
      "โดยมูลนิธิวิกิมี เดีย\n",
      "โดยมูลนิธิวิกิมี ดำเนินการ\n",
      "วิกิพีเดีย ดำเนินการ\n",
      " หน้า\n",
      "หน้า หลัก\n",
      "หน้า คำนวณlog\n",
      "วิกิพีเดีย หลัก\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Create data samples\n",
    "vocab_size = len(dictionary)\n",
    "skip_window = 1       # How many words to consider left and right.\n",
    "\n",
    "sample_set= dataset[:10]\n",
    "sampling_table = sequence.make_sampling_table(vocab_size)\n",
    "#TO DO#3 check out keras source code and find out how their sampling technique works. Describe it in your own words.\n",
    "'''\n",
    "    ###################################################  Answer  #############################################################\n",
    "\n",
    "    A skipgram model receive an input as a word vector and generate a one hot vector of the center word with 1 skip_window around\n",
    "    and find around 1 skip_window proability with make_sampling_table command ,so \n",
    "    and choose the word around with the highest proability as a positive sample like a binary classification.\n",
    "\n",
    "    ###########################################################################################################################\n",
    "'''\n",
    "couples, labels = skipgrams(sample_set, vocab_size, window_size=skip_window, sampling_table=sampling_table)\n",
    "word_target, word_context = zip(*couples)\n",
    "word_target = np.array(word_target, dtype=\"int32\")\n",
    "word_context = np.array(word_context, dtype=\"int32\")\n",
    "\n",
    "print(couples, labels)\n",
    "\n",
    "for i in range(8):\n",
    "    print(reverse_dictionary[couples[i][0]],reverse_dictionary[couples[i][1]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F6UL0FhEi-X6"
   },
   "source": [
    "# Step 4: create the skip-gram model\n",
    "## <font color='blue'>Homework Question 4:</font>\n",
    " <font color='blue'>Q4:  In your own words, discuss why Sigmoid is chosen as the activation function in the  skip-gram model.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "colab_type": "code",
    "id": "kq7Eh9pXi-X7",
    "outputId": "0d07f4a3-5b31-44da-b83f-209dabee2e2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 1, 32)        3587392     input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, 1, 32)        3587392     input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 1, 1)         0           embedding_4[0][0]                \n",
      "                                                                 embedding_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 1)            0           dot_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 1)            0           reshape_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 7,174,784\n",
      "Trainable params: 7,174,784\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#reference: https://github.com/nzw0301/keras-examples/blob/master/Skip-gram-with-NS.ipynb\n",
    "dim_embedddings = 32\n",
    "V= len(dictionary)\n",
    "\n",
    "#step1: select the embedding of the target word from W\n",
    "w_inputs = Input(shape=(1, ), dtype='int32')\n",
    "w = Embedding(V, dim_embedddings)(w_inputs)\n",
    "\n",
    "#step2: select the embedding of the context word from C\n",
    "c_inputs = Input(shape=(1, ), dtype='int32')\n",
    "c  = Embedding(V, dim_embedddings)(c_inputs)\n",
    "\n",
    "#step3: compute the dot product:c_k*v_j\n",
    "o = Dot(axes=2)([w, c])\n",
    "o = Reshape((1,), input_shape=(1, 1))(o)\n",
    "\n",
    "#step4: normailize dot products into probability\n",
    "o = Activation('sigmoid')(o)\n",
    "#TO DO#4 Question: Why sigmoid?\n",
    "'''\n",
    "  #######################################################################  Answer of Why sigmoid?  ####################################################################### \n",
    "\n",
    "  Multi classification task with softmax is too slow because It mean the length of vocabulary multi class, so the output vector may be 10000000 class. \n",
    "  we might change the task to a binary classification that is skip-grams (0 for not a couple of word, 1 for a couple of word) with sigmoid instead with negative sampling .\n",
    "\n",
    "  #########################################################################################################################################################################\n",
    "'''\n",
    "SkipGram = Model(inputs=[w_inputs, c_inputs], outputs=o)\n",
    "SkipGram.summary()\n",
    "opt=Adam(lr=0.01)\n",
    "SkipGram.compile(loss='binary_crossentropy', optimizer=opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "MgR5p_h1i-X9",
    "outputId": "91c111de-ba11-4bd7-cb6b-dfeef967765a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "0.69315165 0\n",
      "0.69312096 100000\n",
      "0.69308937 200000\n",
      "0.6930213 300000\n",
      "0.69290763 400000\n",
      "0.69271946 500000\n",
      "0.6924523 600000\n",
      "0.6920628 700000\n",
      "0.6914731 800000\n",
      "0.6906833 900000\n",
      "0.6896429 1000000\n",
      "0.68835855 1100000\n",
      "0.68672246 1200000\n",
      "0.6846438 1300000\n",
      "0.68228185 1400000\n",
      "0.67931986 1500000\n",
      "0.6756787 1600000\n",
      "0.66923994 0\n",
      "0.66514516 100000\n",
      "0.65961295 200000\n",
      "0.65174717 300000\n",
      "0.6438066 400000\n",
      "0.63489115 500000\n",
      "0.6251258 600000\n",
      "0.61583066 700000\n",
      "0.6060089 800000\n",
      "0.594386 900000\n",
      "0.5814119 1000000\n",
      "0.5690461 1100000\n",
      "0.5550006 1200000\n",
      "0.54028165 1300000\n",
      "0.52714646 1400000\n",
      "0.5120137 1500000\n",
      "0.4950847 1600000\n",
      "0.46456814 0\n",
      "0.4537776 100000\n",
      "0.43747854 200000\n",
      "0.4144349 300000\n",
      "0.39771774 400000\n",
      "0.38064986 500000\n",
      "0.3608763 600000\n",
      "0.34867433 700000\n",
      "0.3407871 800000\n",
      "0.3283194 900000\n",
      "0.31433374 1000000\n",
      "0.30424708 1100000\n",
      "0.29361713 1200000\n",
      "0.28448236 1300000\n",
      "0.28038 1400000\n",
      "0.27436388 1500000\n",
      "0.2670767 1600000\n",
      "0.23507935 0\n",
      "0.23994696 100000\n",
      "0.23578498 200000\n",
      "0.22181827 300000\n",
      "0.21995093 400000\n",
      "0.21722032 500000\n",
      "0.2054864 600000\n",
      "0.2068968 700000\n",
      "0.21500605 800000\n",
      "0.21480574 900000\n",
      "0.21137777 1000000\n",
      "0.2098007 1100000\n",
      "0.20804954 1200000\n",
      "0.20747012 1300000\n",
      "0.21140036 1400000\n",
      "0.21291718 1500000\n",
      "0.21298966 1600000\n",
      "0.18295023 0\n",
      "0.19282262 100000\n",
      "0.19381753 200000\n",
      "0.18308395 300000\n",
      "0.1852735 400000\n",
      "0.18533602 500000\n",
      "0.17489278 600000\n",
      "0.179164 700000\n",
      "0.18838882 800000\n",
      "0.19029161 900000\n",
      "0.18870987 1000000\n",
      "0.18777537 1100000\n",
      "0.18710758 1200000\n",
      "0.18742022 1300000\n",
      "0.19202745 1400000\n",
      "0.19416215 1500000\n",
      "0.19645065 1600000\n"
     ]
    }
   ],
   "source": [
    "# you don't have to spend too much time training for your homework, you are allowed to do it on a smaller corpus\n",
    "# currently the dataset is 1/20 of the full text file.\n",
    "for _ in range(5):\n",
    "    prev_i=0\n",
    "    #it is likely that your GPU won't be able to handle large input\n",
    "    #just do it 100000 words at a time\n",
    "    for i in range(len(dataset)//100000):\n",
    "        #generate skipgrams\n",
    "        data, labels = skipgrams(sequence=dataset[prev_i*100000:(i*100000)+100000], vocabulary_size=V, window_size=2, negative_samples=4.)\n",
    "        x = [np.array(x) for x in zip(*data)]\n",
    "        y = np.array(labels, dtype=np.int32)\n",
    "        if x:\n",
    "            loss = SkipGram.train_on_batch(x, y)\n",
    "        prev_i = i \n",
    "        print(loss,i*100000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sY69_WFHi-X_"
   },
   "outputs": [],
   "source": [
    "SkipGram.save_weights('my_skipgram32_weights-hw.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "7UD13eKki-YA",
    "outputId": "e76f509a-add6-41d6-da52-42807fe06b71",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00696474  0.00201385  0.01166249 ...  0.02834919  0.04179854\n",
      "  -0.0412469 ]\n",
      " [-0.61383915 -0.6563922  -0.5923705  ...  0.6761808  -0.5882664\n",
      "   0.6094683 ]\n",
      " [-0.56639445 -0.59205955 -0.66191715 ...  0.6394608  -0.587136\n",
      "   0.6385333 ]\n",
      " ...\n",
      " [ 0.01673509 -0.04318354  0.03632034 ... -0.04882034 -0.00669356\n",
      "   0.04439757]\n",
      " [-0.03680561 -0.03709161 -0.03314473 ... -0.02201749  0.03523887\n",
      "   0.01686216]\n",
      " [ 0.00256364 -0.04951977 -0.0125877  ...  0.02965248  0.03053318\n",
      "  -0.03666181]]\n"
     ]
    }
   ],
   "source": [
    "#Get weight of the embedding layer\n",
    "final_embeddings=SkipGram.get_weights()[0]\n",
    "print(final_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "2bnIJUSME2R4",
    "outputId": "44b302c5-ac9b-4967-e5cd-f8093025cee2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112106, 32)"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8ovPmh6Ri-YC"
   },
   "source": [
    "# Step 5: Intrinsic Evaluation: Word Vector Analogies\n",
    "## <font color='blue'>Homework Question 5: </font>\n",
    "<font color='blue'> Read section 2.1 and 2.3 in this [lecture note](http://web.stanford.edu/class/cs224n/readings/cs224n-2019-notes02-wordvecs2.pdf). Come up with 10 semantic analogy examples and report results produced by your word embeddings </font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lsCxSaYX9hUx"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def similarity(u, v):\n",
    "    return np.squeeze(cosine_similarity(u.reshape(1, -1), v.reshape(1, -1)))\n",
    "\n",
    "def complete_analogy(word_a, word_b, word_c, embeddings_index):\n",
    "    \n",
    "    # Get the word embeddings v_a, v_b and v_c \n",
    "    e_a, e_b, e_c = embeddings_index[dictionary[word_a]], embeddings_index[dictionary[word_b]], embeddings_index[dictionary[word_c]]\n",
    "    \n",
    "    words = dictionary.keys()\n",
    "    max_cosine_sim = -100              # Initialize max_cosine_sim to a large negative number\n",
    "    best_word = None                   # Initialize best_word with None, it will help keep track of the word to output\n",
    "\n",
    "    # loop over the whole word vector set\n",
    "    for w in words:        \n",
    "        # to avoid best_word being one of the input words, pass on them.\n",
    "        if w in [word_a, word_b, word_c] :\n",
    "            continue\n",
    "        \n",
    "        # Compute cosine similarity between the vector (e_b - e_a) and the vector ((w's vector representation) - e_c)\n",
    "        cosine_sim = similarity(e_b - e_a + e_c, embeddings_index[dictionary[w]])\n",
    "        \n",
    "        # If the cosine_sim is more than the max_cosine_sim seen so far,\n",
    "            # then: set the new max_cosine_sim to the current cosine_sim and the best_word to the current word\n",
    "            \n",
    "        if cosine_sim > max_cosine_sim:\n",
    "            max_cosine_sim = cosine_sim\n",
    "            best_word = w\n",
    "        \n",
    "    return best_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "jE5bdug29haS",
    "outputId": "83972408-d636-4912-fd7b-50fece31165a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ซีก'"
      ]
     },
     "execution_count": 56,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_analogy('สิงหาคม', 'ธันวาคม', 'ชาย', final_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "CqrH4AAb9hc2",
    "outputId": "6bb80401-c953-4194-e7c4-0e95d8077115"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'สันสกฤต'"
      ]
     },
     "execution_count": 47,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_analogy('สิงหาคม', 'ธันวาคม', 'อังกฤษ', final_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "8NRQssZP9hXy",
    "outputId": "a7b2aab7-ff5e-4746-ec7e-5ddb5ed56a7d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ลัทธิ'"
      ]
     },
     "execution_count": 48,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_analogy('แผ่นดิน', 'เกาะ', 'อังกฤษ', final_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "jMrjA08s9hMT",
    "outputId": "f5f4e9c5-7aa9-44ae-b3ae-275bf456f2b6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'หน่วย'"
      ]
     },
     "execution_count": 49,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_analogy('แผ่นดิน', 'เกาะ', 'ประเทศ', final_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "U9csFjpquNNJ",
    "outputId": "5ab2cb0d-d707-46bc-ef5b-a6121ab6182b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'สุด'"
      ]
     },
     "execution_count": 50,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_analogy('อาณาจักร', 'ประเทศ', 'ชาย', final_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "uI8qIqY1Sxaj",
    "outputId": "fb1c30e4-b97d-4ee5-9332-add165cc20ff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'อุบัติ'"
      ]
     },
     "execution_count": 51,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_analogy('ระยะ', 'กิโลเมตร', 'เวลา', final_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "nVZ_RMSSuN-D",
    "outputId": "e56b8c6a-7831-47cc-9d68-9e4949071dc9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ชีอะห์'"
      ]
     },
     "execution_count": 52,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_analogy('ชาย', 'หญิง', 'พระราชา', final_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "QgMVERoDuOF4",
    "outputId": "6bd52da5-e1fd-4fe5-db31-0ec8993e9a9f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ภาษาศาสตร์'"
      ]
     },
     "execution_count": 53,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_analogy('ระยะ', 'กิโลเมตร', 'น้ำหนัก', final_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "SBHapO3JuOx4",
    "outputId": "5540f755-3da6-42b9-c950-42db3083c57a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'กิ'"
      ]
     },
     "execution_count": 54,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_analogy('เหนือ', 'ใต้', 'ตะวันตก', final_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "RGIb29rAuO2b",
    "outputId": "e4c71883-8e83-4254-f668-dea30b5f7b3f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'เขน'"
      ]
     },
     "execution_count": 55,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_analogy('ไป', 'มา', 'รับ', final_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The complete_analogy function return the word vector that have maximum cosine similarity with word target - 3rd position input\n",
    "and the 1st and 2nd position input.\n",
    "\n",
    "The result is return the word vector that have maximum cosine similariy but have no language meaning\n",
    "Its may be caused by the tokenizer or the word embedding  isn't have enough accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sLqG8WaNi-YE"
   },
   "source": [
    "# Step 6: Extrinsic Evaluation\n",
    "\n",
    "## <font color='blue'>Homework Question6:</font>\n",
    "<font color='blue'>\n",
    "Use the word embeddings from the skip-gram model as pre-trained weights in a classification model. Compare the result the with the same classification model that does not use the pre-trained weights. \n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dBPutcxEi-YF"
   },
   "outputs": [],
   "source": [
    "all_news_filepath = glob.glob('BEST-TrainingSet/news/*.txt')\n",
    "all_novel_filepath = glob.glob('BEST-TrainingSet/novel/*.txt')\n",
    "all_article_filepath = glob.glob('BEST-TrainingSet/article/*.txt')\n",
    "all_encyclopedia_filepath = glob.glob('BEST-TrainingSet/encyclopedia/*.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZaX-L5n4i-YG"
   },
   "outputs": [],
   "source": [
    "#preparing data for the classificaiton model\n",
    "#In your homework, we will only use the first 2000 words in each text file\n",
    "#any text file that has less than 2000 words will be padded\n",
    "#reason:just to make this homework feasible under limited time and resource\n",
    "max_length = 2000\n",
    "def word_to_index(word):\n",
    "    if word in dictionary:\n",
    "        return dictionary[word]\n",
    "    else:#if unknown\n",
    "        return dictionary[\"UNK\"]\n",
    "\n",
    "\n",
    "def prep_data():\n",
    "    input_text = list()\n",
    "    for textfile_path in [all_news_filepath, all_novel_filepath, all_article_filepath, all_encyclopedia_filepath]:\n",
    "        for input_file in textfile_path:\n",
    "            f = open(input_file,\"r\") #open file with name of \"*.txt\"\n",
    "            text = re.sub(r'\\|', ' ', f.read()) # replace separation symbol with white space           \n",
    "            text = re.sub(r'<\\W?\\w+>', '', text)# remove <NE> </NE> <AB> </AB> tags\n",
    "            text = text.split() #split() method without an argument splits on whitespace \n",
    "            indexed_text = list(map(lambda x:word_to_index(x), text[:max_length])) #map raw word string to its index   \n",
    "            if 'news' in input_file:\n",
    "                input_text.append([indexed_text,0]) \n",
    "            elif 'novel' in input_file:\n",
    "                input_text.append([indexed_text,1]) \n",
    "            elif 'article' in input_file:\n",
    "                input_text.append([indexed_text,2]) \n",
    "            elif 'encyclopedia' in input_file:\n",
    "                input_text.append([indexed_text,3]) \n",
    "            \n",
    "            f.close()\n",
    "    random.shuffle(input_text)\n",
    "    return input_text\n",
    "\n",
    "input_data = prep_data()\n",
    "train_data = input_data[:int(len(input_data)*0.6)]\n",
    "val_data = input_data[int(len(input_data)*0.6):int(len(input_data)*0.8)]\n",
    "test_data = input_data[int(len(input_data)*0.8):]\n",
    "\n",
    "train_input = [data[0] for data in train_data]\n",
    "train_input = sequence.pad_sequences(train_input, maxlen=max_length) #padding\n",
    "train_target = [data[1] for data in train_data]\n",
    "train_target=to_categorical(train_target, num_classes=4)\n",
    "\n",
    "\n",
    "\n",
    "val_input = [data[0] for data in val_data]\n",
    "val_input = sequence.pad_sequences(val_input, maxlen=max_length) #padding\n",
    "val_target = [data[1] for data in val_data]\n",
    "val_target=to_categorical(val_target, num_classes=4)\n",
    "\n",
    "test_input = [data[0] for data in test_data]\n",
    "test_input = sequence.pad_sequences(test_input, maxlen=max_length) #padding\n",
    "test_target = [data[1] for data in test_data]\n",
    "test_target=to_categorical(test_target, num_classes=4)\n",
    "\n",
    "del input_data, val_data,train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "id": "syrKnUxWi-YI",
    "outputId": "1a9b3aa4-e3b8-47d3-a4e1-15df00075620"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 2000, 32)          3587392   \n",
      "_________________________________________________________________\n",
      "gru_3 (GRU)                  (None, 32)                6240      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               3300      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 4)                 404       \n",
      "=================================================================\n",
      "Total params: 3,597,336\n",
      "Trainable params: 3,597,336\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#the classification model\n",
    "#TO DO#6 find out how to initialize your embedding layer with pre-trained weights, evaluate and observe\n",
    "#don't forget to compare it with the same model that does not use pre-trained weights\n",
    "#you can use your own model too! and feel free to customize this model as you wish\n",
    "cls_model = Sequential()\n",
    "cls_model.add(Embedding(len(dictionary), 32, input_length=max_length))\n",
    "cls_model.layers[0].set_weights([final_embeddings])\n",
    "cls_model.add(GRU(32))\n",
    "cls_model.add(Dropout(0.2))\n",
    "cls_model.add(Dense(100, activation='relu'))\n",
    "cls_model.add(Dense(4, activation='softmax'))\n",
    "cls_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "cls_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Bou-poz2BqDS",
    "outputId": "ebf274f7-3842-4df7-824f-32e2ecdeb1d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Train on 303 samples, validate on 101 samples\n",
      "Epoch 1/50\n",
      " - 34s - loss: 1.3690 - acc: 0.3399 - val_loss: 1.3709 - val_acc: 0.3465\n",
      "Epoch 2/50\n",
      " - 33s - loss: 1.3379 - acc: 0.3861 - val_loss: 1.3587 - val_acc: 0.3465\n",
      "Epoch 3/50\n",
      " - 32s - loss: 1.3378 - acc: 0.3861 - val_loss: 1.3521 - val_acc: 0.3465\n",
      "Epoch 4/50\n",
      " - 32s - loss: 1.3323 - acc: 0.3861 - val_loss: 1.3525 - val_acc: 0.3465\n",
      "Epoch 5/50\n",
      " - 32s - loss: 1.3281 - acc: 0.3861 - val_loss: 1.3560 - val_acc: 0.3465\n",
      "Epoch 6/50\n",
      " - 32s - loss: 1.3255 - acc: 0.3861 - val_loss: 1.3535 - val_acc: 0.3465\n",
      "Epoch 7/50\n",
      " - 32s - loss: 1.3210 - acc: 0.3861 - val_loss: 1.3531 - val_acc: 0.3465\n",
      "Epoch 8/50\n",
      " - 32s - loss: 1.3131 - acc: 0.3861 - val_loss: 1.3513 - val_acc: 0.3465\n",
      "Epoch 9/50\n",
      " - 32s - loss: 1.3133 - acc: 0.3861 - val_loss: 1.3497 - val_acc: 0.3465\n",
      "Epoch 10/50\n",
      " - 33s - loss: 1.2992 - acc: 0.3861 - val_loss: 1.3443 - val_acc: 0.3465\n",
      "Epoch 11/50\n",
      " - 33s - loss: 1.2864 - acc: 0.3861 - val_loss: 1.3431 - val_acc: 0.3465\n",
      "Epoch 12/50\n",
      " - 33s - loss: 1.2527 - acc: 0.3861 - val_loss: 1.3400 - val_acc: 0.3465\n",
      "Epoch 13/50\n",
      " - 32s - loss: 1.2399 - acc: 0.3927 - val_loss: 1.3303 - val_acc: 0.3465\n",
      "Epoch 14/50\n",
      " - 32s - loss: 1.1974 - acc: 0.4224 - val_loss: 1.3125 - val_acc: 0.3465\n",
      "Epoch 15/50\n",
      " - 32s - loss: 1.1187 - acc: 0.5347 - val_loss: 1.2944 - val_acc: 0.3762\n",
      "Epoch 16/50\n",
      " - 33s - loss: 1.0031 - acc: 0.6238 - val_loss: 1.2412 - val_acc: 0.4356\n",
      "Epoch 17/50\n",
      " - 32s - loss: 0.7924 - acc: 0.7228 - val_loss: 1.1852 - val_acc: 0.4554\n",
      "Epoch 18/50\n",
      " - 32s - loss: 0.6422 - acc: 0.7525 - val_loss: 1.1937 - val_acc: 0.4851\n",
      "Epoch 19/50\n",
      " - 32s - loss: 0.4950 - acc: 0.8647 - val_loss: 1.2151 - val_acc: 0.4752\n",
      "Epoch 20/50\n",
      " - 32s - loss: 0.3259 - acc: 0.9406 - val_loss: 1.3176 - val_acc: 0.4752\n",
      "Epoch 21/50\n",
      " - 33s - loss: 0.1969 - acc: 0.9736 - val_loss: 1.3797 - val_acc: 0.4653\n",
      "Epoch 22/50\n",
      " - 32s - loss: 0.1265 - acc: 0.9868 - val_loss: 1.5377 - val_acc: 0.5149\n",
      "Epoch 23/50\n",
      " - 32s - loss: 0.0796 - acc: 0.9967 - val_loss: 1.6470 - val_acc: 0.5347\n",
      "Epoch 24/50\n",
      " - 32s - loss: 0.0501 - acc: 0.9967 - val_loss: 1.9289 - val_acc: 0.5050\n",
      "Epoch 25/50\n",
      " - 32s - loss: 0.0415 - acc: 0.9967 - val_loss: 2.0406 - val_acc: 0.4950\n",
      "Epoch 26/50\n",
      " - 32s - loss: 0.0271 - acc: 1.0000 - val_loss: 1.8882 - val_acc: 0.5248\n",
      "Epoch 27/50\n",
      " - 32s - loss: 0.0250 - acc: 0.9934 - val_loss: 2.5384 - val_acc: 0.4158\n",
      "Epoch 28/50\n",
      " - 32s - loss: 0.0216 - acc: 1.0000 - val_loss: 2.2487 - val_acc: 0.4950\n",
      "Epoch 29/50\n",
      " - 33s - loss: 0.0132 - acc: 1.0000 - val_loss: 1.9756 - val_acc: 0.5347\n",
      "Epoch 30/50\n",
      " - 32s - loss: 0.0104 - acc: 1.0000 - val_loss: 2.1625 - val_acc: 0.5446\n",
      "Epoch 31/50\n",
      " - 32s - loss: 0.0098 - acc: 1.0000 - val_loss: 2.3045 - val_acc: 0.5248\n",
      "Epoch 32/50\n",
      " - 32s - loss: 0.0061 - acc: 1.0000 - val_loss: 2.4109 - val_acc: 0.4950\n",
      "Epoch 33/50\n",
      " - 32s - loss: 0.0049 - acc: 1.0000 - val_loss: 2.3201 - val_acc: 0.5248\n",
      "Epoch 34/50\n",
      " - 32s - loss: 0.0040 - acc: 1.0000 - val_loss: 2.3622 - val_acc: 0.5050\n",
      "Epoch 35/50\n",
      " - 32s - loss: 0.0033 - acc: 1.0000 - val_loss: 2.3597 - val_acc: 0.5347\n",
      "Epoch 36/50\n",
      " - 32s - loss: 0.0036 - acc: 1.0000 - val_loss: 2.4374 - val_acc: 0.5248\n",
      "Epoch 37/50\n",
      " - 32s - loss: 0.0039 - acc: 1.0000 - val_loss: 2.4195 - val_acc: 0.4950\n",
      "Epoch 38/50\n",
      " - 32s - loss: 0.0027 - acc: 1.0000 - val_loss: 2.3336 - val_acc: 0.5644\n",
      "Epoch 39/50\n",
      " - 32s - loss: 0.0025 - acc: 1.0000 - val_loss: 2.3760 - val_acc: 0.5446\n",
      "Epoch 40/50\n",
      " - 32s - loss: 0.0025 - acc: 1.0000 - val_loss: 2.4593 - val_acc: 0.5545\n",
      "Epoch 41/50\n",
      " - 32s - loss: 0.0026 - acc: 1.0000 - val_loss: 2.6028 - val_acc: 0.4653\n",
      "Epoch 42/50\n",
      " - 32s - loss: 0.0020 - acc: 1.0000 - val_loss: 2.6339 - val_acc: 0.4752\n",
      "Epoch 43/50\n",
      " - 32s - loss: 0.0018 - acc: 1.0000 - val_loss: 2.5754 - val_acc: 0.5050\n",
      "Epoch 44/50\n",
      " - 32s - loss: 0.0014 - acc: 1.0000 - val_loss: 2.5534 - val_acc: 0.5347\n",
      "Epoch 45/50\n",
      " - 32s - loss: 0.0020 - acc: 1.0000 - val_loss: 2.5228 - val_acc: 0.5644\n",
      "Epoch 46/50\n",
      " - 32s - loss: 0.0015 - acc: 1.0000 - val_loss: 2.5714 - val_acc: 0.5050\n",
      "Epoch 47/50\n",
      " - 32s - loss: 0.0015 - acc: 1.0000 - val_loss: 2.6606 - val_acc: 0.4554\n",
      "Epoch 48/50\n",
      " - 33s - loss: 0.0014 - acc: 1.0000 - val_loss: 2.6916 - val_acc: 0.4851\n",
      "Epoch 49/50\n",
      " - 32s - loss: 0.0012 - acc: 1.0000 - val_loss: 2.6326 - val_acc: 0.5347\n",
      "Epoch 50/50\n",
      " - 32s - loss: 7.8364e-04 - acc: 1.0000 - val_loss: 2.6118 - val_acc: 0.5050\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe04b024240>"
      ]
     },
     "execution_count": 40,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Train...')\n",
    "cls_model.fit(train_input, train_target,\n",
    "          epochs=50,verbose=2,\n",
    "          validation_data=[val_input, val_target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "VrWkXNvOBaxU",
    "outputId": "ddcfef8b-b342-412e-d195-dca751cfa6a2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.2955935562358185, 0.5196078431372549]"
      ]
     },
     "execution_count": 41,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_model.evaluate(test_input,test_target,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "id": "guqOjEWxBa7p",
    "outputId": "23628936-2dc3-4dee-bf15-6ff4c6209b28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, 2000, 32)          3587392   \n",
      "_________________________________________________________________\n",
      "gru_4 (GRU)                  (None, 32)                6240      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 100)               3300      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 4)                 404       \n",
      "=================================================================\n",
      "Total params: 3,597,336\n",
      "Trainable params: 3,597,336\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cls_model = Sequential()\n",
    "cls_model.add(Embedding(len(dictionary), 32, input_length=max_length))\n",
    "cls_model.add(GRU(32))\n",
    "cls_model.add(Dropout(0.2))\n",
    "cls_model.add(Dense(100, activation='relu'))\n",
    "cls_model.add(Dense(4, activation='softmax'))\n",
    "cls_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "cls_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "-0yBl-lAGU-v",
    "outputId": "b91f9fe6-76eb-4b61-90ea-a4f9bfe10983"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Train on 303 samples, validate on 101 samples\n",
      "Epoch 1/50\n",
      " - 34s - loss: 1.3820 - acc: 0.3597 - val_loss: 1.3794 - val_acc: 0.3465\n",
      "Epoch 2/50\n",
      " - 32s - loss: 1.3668 - acc: 0.3861 - val_loss: 1.3714 - val_acc: 0.3465\n",
      "Epoch 3/50\n",
      " - 33s - loss: 1.3458 - acc: 0.3861 - val_loss: 1.3624 - val_acc: 0.3465\n",
      "Epoch 4/50\n",
      " - 33s - loss: 1.3171 - acc: 0.3861 - val_loss: 1.3554 - val_acc: 0.3465\n",
      "Epoch 5/50\n",
      " - 33s - loss: 1.2714 - acc: 0.3861 - val_loss: 1.3490 - val_acc: 0.3465\n",
      "Epoch 6/50\n",
      " - 33s - loss: 1.1935 - acc: 0.3861 - val_loss: 1.3242 - val_acc: 0.3465\n",
      "Epoch 7/50\n",
      " - 33s - loss: 1.0376 - acc: 0.4653 - val_loss: 1.2750 - val_acc: 0.4356\n",
      "Epoch 8/50\n",
      " - 33s - loss: 0.8323 - acc: 0.7294 - val_loss: 1.1855 - val_acc: 0.4752\n",
      "Epoch 9/50\n",
      " - 33s - loss: 0.6845 - acc: 0.8713 - val_loss: 1.1693 - val_acc: 0.5050\n",
      "Epoch 10/50\n",
      " - 33s - loss: 0.5241 - acc: 0.9538 - val_loss: 1.1296 - val_acc: 0.5446\n",
      "Epoch 11/50\n",
      " - 33s - loss: 0.3670 - acc: 0.9670 - val_loss: 1.0915 - val_acc: 0.5446\n",
      "Epoch 12/50\n",
      " - 33s - loss: 0.2325 - acc: 0.9868 - val_loss: 1.2297 - val_acc: 0.5545\n",
      "Epoch 13/50\n",
      " - 33s - loss: 0.1332 - acc: 0.9901 - val_loss: 1.1413 - val_acc: 0.5743\n",
      "Epoch 14/50\n",
      " - 32s - loss: 0.0657 - acc: 0.9934 - val_loss: 1.2215 - val_acc: 0.5842\n",
      "Epoch 15/50\n",
      " - 33s - loss: 0.0403 - acc: 1.0000 - val_loss: 1.3790 - val_acc: 0.6040\n",
      "Epoch 16/50\n",
      " - 33s - loss: 0.0215 - acc: 1.0000 - val_loss: 1.3274 - val_acc: 0.6238\n",
      "Epoch 17/50\n",
      " - 33s - loss: 0.0169 - acc: 1.0000 - val_loss: 1.4370 - val_acc: 0.6436\n",
      "Epoch 18/50\n",
      " - 33s - loss: 0.0141 - acc: 1.0000 - val_loss: 1.4393 - val_acc: 0.6436\n",
      "Epoch 19/50\n",
      " - 33s - loss: 0.0106 - acc: 1.0000 - val_loss: 1.4751 - val_acc: 0.6436\n",
      "Epoch 20/50\n",
      " - 33s - loss: 0.0059 - acc: 1.0000 - val_loss: 1.5385 - val_acc: 0.6535\n",
      "Epoch 21/50\n",
      " - 33s - loss: 0.0051 - acc: 1.0000 - val_loss: 1.5433 - val_acc: 0.6436\n",
      "Epoch 22/50\n",
      " - 33s - loss: 0.0045 - acc: 1.0000 - val_loss: 1.5433 - val_acc: 0.6634\n",
      "Epoch 23/50\n",
      " - 33s - loss: 0.0035 - acc: 1.0000 - val_loss: 1.5563 - val_acc: 0.6634\n",
      "Epoch 24/50\n",
      " - 33s - loss: 0.0031 - acc: 1.0000 - val_loss: 1.5702 - val_acc: 0.6634\n",
      "Epoch 25/50\n",
      " - 33s - loss: 0.0033 - acc: 1.0000 - val_loss: 1.6397 - val_acc: 0.6832\n",
      "Epoch 26/50\n",
      " - 33s - loss: 0.0021 - acc: 1.0000 - val_loss: 1.6456 - val_acc: 0.6733\n",
      "Epoch 27/50\n",
      " - 33s - loss: 0.0020 - acc: 1.0000 - val_loss: 1.6593 - val_acc: 0.6733\n",
      "Epoch 28/50\n",
      " - 33s - loss: 0.0015 - acc: 1.0000 - val_loss: 1.6613 - val_acc: 0.6733\n",
      "Epoch 29/50\n",
      " - 33s - loss: 0.0017 - acc: 1.0000 - val_loss: 1.6460 - val_acc: 0.6634\n",
      "Epoch 30/50\n",
      " - 33s - loss: 0.0015 - acc: 1.0000 - val_loss: 1.6490 - val_acc: 0.6634\n",
      "Epoch 31/50\n",
      " - 33s - loss: 0.0013 - acc: 1.0000 - val_loss: 1.6560 - val_acc: 0.6436\n",
      "Epoch 32/50\n",
      " - 33s - loss: 9.7319e-04 - acc: 1.0000 - val_loss: 1.6868 - val_acc: 0.6634\n",
      "Epoch 33/50\n",
      " - 33s - loss: 0.0016 - acc: 1.0000 - val_loss: 1.6943 - val_acc: 0.6634\n",
      "Epoch 34/50\n",
      " - 33s - loss: 0.0010 - acc: 1.0000 - val_loss: 1.6716 - val_acc: 0.6535\n",
      "Epoch 35/50\n",
      " - 33s - loss: 0.0013 - acc: 1.0000 - val_loss: 1.6996 - val_acc: 0.6634\n",
      "Epoch 36/50\n",
      " - 32s - loss: 7.7878e-04 - acc: 1.0000 - val_loss: 1.7614 - val_acc: 0.6733\n",
      "Epoch 37/50\n",
      " - 33s - loss: 8.5881e-04 - acc: 1.0000 - val_loss: 1.7722 - val_acc: 0.6733\n",
      "Epoch 38/50\n",
      " - 33s - loss: 0.0011 - acc: 1.0000 - val_loss: 1.7408 - val_acc: 0.6634\n",
      "Epoch 39/50\n",
      " - 33s - loss: 7.2885e-04 - acc: 1.0000 - val_loss: 1.7538 - val_acc: 0.6733\n",
      "Epoch 40/50\n",
      " - 32s - loss: 7.6716e-04 - acc: 1.0000 - val_loss: 1.7663 - val_acc: 0.6733\n",
      "Epoch 41/50\n",
      " - 33s - loss: 6.0780e-04 - acc: 1.0000 - val_loss: 1.7797 - val_acc: 0.6634\n",
      "Epoch 42/50\n",
      " - 33s - loss: 0.0014 - acc: 1.0000 - val_loss: 1.8181 - val_acc: 0.6436\n",
      "Epoch 43/50\n",
      " - 33s - loss: 7.0750e-04 - acc: 1.0000 - val_loss: 1.8609 - val_acc: 0.6832\n",
      "Epoch 44/50\n",
      " - 33s - loss: 5.2734e-04 - acc: 1.0000 - val_loss: 1.8964 - val_acc: 0.6832\n",
      "Epoch 45/50\n",
      " - 33s - loss: 3.8365e-04 - acc: 1.0000 - val_loss: 1.8865 - val_acc: 0.6733\n",
      "Epoch 46/50\n",
      " - 33s - loss: 2.9365e-04 - acc: 1.0000 - val_loss: 1.8727 - val_acc: 0.6733\n",
      "Epoch 47/50\n",
      " - 33s - loss: 3.5826e-04 - acc: 1.0000 - val_loss: 1.8674 - val_acc: 0.6733\n",
      "Epoch 48/50\n",
      " - 33s - loss: 3.6894e-04 - acc: 1.0000 - val_loss: 1.8657 - val_acc: 0.6733\n",
      "Epoch 49/50\n",
      " - 33s - loss: 4.0731e-04 - acc: 1.0000 - val_loss: 1.8666 - val_acc: 0.6733\n",
      "Epoch 50/50\n",
      " - 33s - loss: 2.3372e-04 - acc: 1.0000 - val_loss: 1.8751 - val_acc: 0.6733\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe03e2b6cf8>"
      ]
     },
     "execution_count": 43,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Train...')\n",
    "cls_model.fit(train_input, train_target,\n",
    "          epochs=50,verbose=2,\n",
    "          validation_data=[val_input, val_target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Wd9w_9ejBoSJ",
    "outputId": "c59f8566-cde7-4207-f35b-571e603d4bc8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.6213486662098004, 0.6176470576548109]"
      ]
     },
     "execution_count": 44,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_model.evaluate(test_input,test_target,verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model using pretrained embedding have less loss than model not using pretrained embedding on the test set,\n",
    "that is 2.2955935562358185 and 2.6213486662098004.\n",
    "\n",
    "But have accuracy less than compare to the model not using pretrained embedding ."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "thai_skip_gram_homework_for_student.ipynb.txt",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
